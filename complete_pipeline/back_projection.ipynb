{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backprojetion from triangulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import multicam_calibration as mcc\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threed_utils.visualization import plot_triangulations, plot_back_projections\n",
    "from threed_utils.old_triangulation import back_project_points\n",
    "from utils import read_first_frame\n",
    "import xarray as xr\n",
    "import plotly.graph_objects as go\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get triangulation from predictions: mcc, anipose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from one session:\n",
    "from pathlib import Path\n",
    "dir_path = Path(r\"D:\\P05_3DRIG_YE-LP\\e01_mouse_hunting\\v04_mice-hunting\\20240724\\100455\\multicam_video_2024-07-24T10_20_07_cropped_20241209165236\")\n",
    "calibration_path = Path(r\"D:\\P05_3DRIG_YE-LP\\e01_mouse_hunting\\v04_mice-hunting\\20240724\\calibration\\multicam_video_2024-07-24T14_13_45_cropped_20241209165236\\mc_calibration_output_20241212-112458\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get calibration matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('/Users/thomasbush/Documents/Vault/Iurilli_lab/3d_tracking/data/calibration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the matrices:\n",
    "\n",
    "from threed_utils.io import movement_ds_from_anipose_triangulation_df, read_calibration_toml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/thomasbush/Documents/Vault/Iurilli_lab/3d_tracking/data/calibration/mc_calibration_output_20241210-164414/calibration_from_mc.toml\n"
     ]
    }
   ],
   "source": [
    "calibration_paths = sorted(data_dir.glob(\"mc_calibration_output_*\"))\n",
    "last_calibration_path = calibration_paths[-1]\n",
    "\n",
    "all_calib_uvs = np.load(last_calibration_path / \"all_calib_uvs.npy\")\n",
    "calib_toml_path = last_calibration_path / \"calibration_from_mc.toml\"\n",
    "print(calib_toml_path)\n",
    "cam_names, img_sizes, extrinsics, intrinsics = read_calibration_toml(calib_toml_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get triangulated points from both: \n",
    "import xarray as xr\n",
    "\n",
    "slp_dir = Path('/Users/thomasbush/Documents/Vault/Iurilli_lab/3d_tracking/data/video_test')\n",
    "\n",
    "triangulation_path = slp_dir / 'anipose_triangulated_ds.h5'\n",
    "mcc_path = slp_dir / 'mcc_triangulated_ds.h5'\n",
    "anipose_ds = xr.open_dataset(triangulation_path)\n",
    "mcc_ds = xr.open_dataset(mcc_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Dataset.info of <xarray.Dataset> Size: 421kB\n",
       "Dimensions:      (time: 1001, keypoints: 13, individuals: 1, space: 3)\n",
       "Coordinates:\n",
       "  * time         (time) int32 4kB 0 1 2 3 4 5 6 ... 994 995 996 997 998 999 1000\n",
       "  * keypoints    (keypoints) object 104B 'blimbmid' 'flimbmid' ... 'uppermid'\n",
       "  * space        (space) object 24B 'x' 'y' 'z'\n",
       "  * individuals  (individuals) object 8B 'individual_0'\n",
       "Data variables:\n",
       "    confidence   (time, keypoints, individuals) float64 104kB ...\n",
       "    position     (time, space, keypoints, individuals) float64 312kB ...\n",
       "Attributes:\n",
       "    fps:              fps\n",
       "    time_unit:        frames\n",
       "    source_software:  SLEAP_triangulated\n",
       "    source_file:      mcc\n",
       "    ds_type:          poses>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcc_ds.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "arena_path = '/Users/thomasbush/Documents/Vault/Iurilli_lab/3d_tracking/3d-setup/tests/assets/arena_tracked_points.pkl'\n",
    "with open(arena_path, 'rb') as f:\n",
    "    arena_points = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to get store indices from original video to xarray?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_3d_arena(arena_path, extrinsics, intrinsics):\n",
    "    with open(arena_path, 'rb') as f:\n",
    "        points = pickle.load(f)\n",
    "    arena_points = points['points']['arena_coordinates'].squeeze()\n",
    "\n",
    "    arena_3d = mcc.triangulate(arena_points[..., [1, 0]], extrinsics, intrinsics)\n",
    "    return arena_3d.reshape((8, 1, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backproject_triangulated_points(xarray_ds, extrinsics, intrinsics, frame_n, cam_names, arena_3d):\n",
    "    \"\"\"\n",
    "    Back-project 3D triangulated points to 2D camera coordinates for a specific frame.\n",
    "    \n",
    "    Args:\n",
    "        xarray_ds (xarray.Dataset): Dataset containing triangulated points with dimensions:\n",
    "            (time: 1001, keypoints: 13, individuals: 1, space: 3)\n",
    "        extrinsics (list): List of extrinsic matrices for each camera\n",
    "        intrinsics (list): List of intrinsic matrices for each camera\n",
    "        frame_n (int): Frame number to process\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary of back-projected points for each camera\n",
    "    \"\"\"\n",
    "    video_paths = sorted(slp_dir.glob(\"*.mp4\"))\n",
    "\n",
    "    camera_matrices = [i[0] for i in intrinsics]\n",
    "    # Extract 3D points for the specified frame\n",
    "    # Shape will be (space, keypoints, individuals)\n",
    "    frame_points = mcc_ds.position.isel(time=frame_n).values.transpose(1, 2, 0)\n",
    "\n",
    "    frame_points = frame_points.squeeze()\n",
    "\n",
    "     # Now shape is (keypoints, space, individuals)\n",
    "    \n",
    "    # Initialize dictionary to store back-projected points for each camera\n",
    "\n",
    "    arena2d = mcc.project_points(arena_3d, extrinsics, camera_matrices)\n",
    "\n",
    "    back_projected = mcc.project_points(frame_points, extrinsics, camera_matrices)\n",
    "\n",
    "    back_projected_points = {camera: [points, arena] for camera, points, arena in zip(cam_names, back_projected, arena2d)}\n",
    "    \n",
    "    \n",
    "    return back_projected_points, frame_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def read_nth_frame(input_file, n):\n",
    "    \"\"\"\n",
    "    Reads the nth frame from the input video file.\n",
    "\n",
    "    Args:\n",
    "        input_file (str or Path): Path to the video file.\n",
    "        n (int): Frame number to read (0-indexed).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The nth frame as an image array.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the frame cannot be read or the frame number is out of bounds.\n",
    "    \"\"\"\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(str(input_file))\n",
    "    \n",
    "    # Check if the video was successfully opened\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Failed to open the video file: {input_file}\")\n",
    "    \n",
    "    # Set the frame position\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if n < 0 or n >= total_frames:\n",
    "        cap.release()\n",
    "        raise ValueError(f\"Frame number {n} is out of bounds for video with {total_frames} frames.\")\n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, n)\n",
    "    \n",
    "    # Read the frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        cap.release()\n",
    "        raise ValueError(f\"Failed to read frame {n} from the video.\")\n",
    "    \n",
    "    # Release the video capture object\n",
    "    cap.release()\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_frames_camera(backprojections, n_frame, video_dir):\n",
    "    \"\"\"\n",
    "    Associates video frames with their corresponding camera keys from backprojections.\n",
    "\n",
    "    Args:\n",
    "        backprojections (dict): Dictionary where keys are camera names (e.g., 'mirror-left')\n",
    "                                and values are backprojected points.\n",
    "        n_frame (int): Frame number to extract.\n",
    "        video_dir (Path): Directory containing the video files.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with keys as camera names and values as tuples:\n",
    "              (frame from video, backprojected points).\n",
    "    \"\"\"\n",
    "    backprojections_frames = {}\n",
    "    video_paths = sorted(video_dir.glob(\"*.mp4\"))\n",
    "\n",
    "    # Regex to extract camera name from video file names\n",
    "    camera_name_regex = re.compile(r\".*_(\\w+(?:-\\w+)?)\\.avi\\.mp4$\")\n",
    "\n",
    "    # Create a map of camera name to video path\n",
    "    video_camera_map = {}\n",
    "    for video_path in video_paths:\n",
    "        match = camera_name_regex.match(video_path.name)\n",
    "        if match:\n",
    "            camera_name = match.group(1)\n",
    "            video_camera_map[camera_name] = video_path\n",
    "        else:\n",
    "            raise ValueError(f\"Could not extract camera name from: {video_path.name}\")\n",
    "\n",
    "    # Match backprojection keys to their corresponding video and extract frames\n",
    "    for camera, points in backprojections.items():\n",
    "        if camera in video_camera_map:\n",
    "            video_path = video_camera_map[camera]\n",
    "            backprojections_frames[camera] = (read_nth_frame(video_path, n_frame), points)\n",
    "        else:\n",
    "            raise KeyError(f\"Camera '{camera}' not found in video files.\")\n",
    "    \n",
    "    return backprojections_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_frames_with_points(camera_data):\n",
    "    \"\"\"\n",
    "    Plots frames with tracked points in subplots, using camera names as titles.\n",
    "\n",
    "    Args:\n",
    "        camera_data (dict): A dictionary where keys are camera names and values are tuples:\n",
    "                            (frame (numpy array), tracked points (list or numpy array)).\n",
    "    \"\"\"\n",
    "    # Determine the number of subplots needed\n",
    "    n_cameras = len(camera_data)\n",
    "    n_cols = 3  # Number of columns in the grid\n",
    "    n_rows = -(-n_cameras // n_cols)  # Ceiling division to get rows\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "\n",
    "    # Flatten axes for easy iteration\n",
    "    axes = axes.flatten() if n_rows > 1 else [axes]\n",
    "    \n",
    "    # Loop over cameras and plot data\n",
    "    for idx, (camera_name, (frame, points)) in enumerate(camera_data.items()):\n",
    "        ax = axes[idx]\n",
    "        ax.imshow(frame)  # Display the frame\n",
    "        points = np.array(points)  # Ensure points are in array form\n",
    "        if len(points) > 0:\n",
    "            ax.scatter(points[0][:, 0], points[0][:, 1], color='red', s=10)\n",
    "            ax.scatter(points[1][:, 0], points[1][:, 1], color='blue', s=10)  # Plot points\n",
    "        ax.set_title(camera_name)\n",
    "        ax.axis('off')  # Turn off axis for a cleaner look\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for i in range(len(camera_data), len(axes)):\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "def plot3d_frame(frame_points3d, arena_3d):\n",
    "    frame_points3d = frame_points3d.squeeze()\n",
    "    arena_3d = arena_3d.squeeze()\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter3d(x=frame_points3d[:, 0], y=frame_points3d[:, 1], z=frame_points3d[:, 2], mode='markers', marker=dict(size=5, color='red')))\n",
    "    #add arena points \n",
    "    fig.add_trace(go.Scatter3d(x=arena_3d[:, 0], y=arena_3d[:, 1], z=arena_3d[:, 2], mode='markers', marker=dict(size=5, color='blue')))\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that combines the previous functions into a single one by calling them:\n",
    "\n",
    "def backprojections_plots(ds, n_frame, video_dir, calibration_dir, arena_path):\n",
    "\n",
    "    '''\n",
    "    args:\n",
    "    -ds : xarray with the triangulated points\n",
    "    -n_frame : int, the frame number to plot\n",
    "    -video_dir : Path, the directory containing the videos and .slp files\n",
    "    -calibration_dir: path to the calibration directory with the toml file \n",
    "    -arena_path: patht to the pickle file containing the arena points\n",
    "\n",
    "    returns:\n",
    "    -plot of the triangulated points in 3d with the arena points\n",
    "    -plot of the backprojections of the triangulated points with respective frames and arena points \n",
    "    '''\n",
    "\n",
    "\n",
    "    # load the calibration matrices:\n",
    "    calibration_path = Path(calibration_dir)\n",
    "    calibration_paths = sorted(calibration_path.glob(\"mc_calibration_output_*\"))\n",
    "    last_calibration_path = calibration_paths[-1]\n",
    "\n",
    "    calib_toml_path = last_calibration_path / \"calibration_from_mc.toml\"\n",
    "    print(calib_toml_path)\n",
    "    cam_names, img_sizes, extrinsics, intrinsics = read_calibration_toml(calib_toml_path)\n",
    "\n",
    "\n",
    "    # get the arena 3d points with same calibration matrices:\n",
    "    arena_3d = get_3d_arena(arena_path, extrinsics, intrinsics)\n",
    "\n",
    "    # get the backprojections and the frame points:\n",
    "    backprojections, frame_points3d = backproject_triangulated_points(ds, extrinsics, intrinsics, n_frame, cam_names, arena_3d)\n",
    "    #plot the frame in 3d\n",
    "    plot3d_frame(frame_points3d, arena_3d)\n",
    "    # get dictionary with camera name, frame and backproject points\n",
    "    cam_frame_points = get_frames_camera(backprojections, n_frame, video_dir)\n",
    "\n",
    "\n",
    "    plot_frames_with_points(cam_frame_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'anipose_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m calibration_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/thomasbush/Documents/Vault/Iurilli_lab/3d_tracking/data/calibration\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m backprojections_plots(\u001b[43manipose_ds\u001b[49m, \u001b[38;5;241m350\u001b[39m, slp_dir, calibration_path, arena_path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'anipose_ds' is not defined"
     ]
    }
   ],
   "source": [
    "calibration_path = '/Users/thomasbush/Documents/Vault/Iurilli_lab/3d_tracking/data/calibration'\n",
    "backprojections_plots(anipose_ds, 350, slp_dir, calibration_path, arena_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try on local data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_path = r\"D:\\P05_3DRIG_YE-LP\\e01_mouse_hunting\\v04_mice-hunting\\20240724\\calibration\\multicam_video_2024-07-24T14_13_45_cropped_20241209165236\"\n",
    "slp_dir = Path(r\"D:\\P05_3DRIG_YE-LP\\e01_mouse_hunting\\test_cropping\\sample_video_for_triangulation\\multicam_video_2024-07-24T10_04_55_cropped_20241104101620\")\n",
    "arena_path = r\"C:\\Users\\SNeurobiology\\code\\3d-setup\\tests\\assets\\arena_tracked_points.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc_ds = xr.open_dataset(slp_dir / 'mcc_triangulated_ds.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\P05_3DRIG_YE-LP\\e01_mouse_hunting\\v04_mice-hunting\\20240724\\calibration\\multicam_video_2024-07-24T14_13_45_cropped_20241209165236\\mc_calibration_output_20241212-112458\\calibration_from_mc.toml\n",
      "(13, 3, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with remapped shapes [original->remapped]: (5,4,4)->(5,newaxis,newaxis) (13,4,1)->(13,newaxis,newaxis)  and requested shape (4,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mbackprojections_plots\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmcc_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslp_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalibration_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marena_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[39], line 33\u001b[0m, in \u001b[0;36mbackprojections_plots\u001b[1;34m(ds, n_frame, video_dir, calibration_dir, arena_path)\u001b[0m\n\u001b[0;32m     30\u001b[0m arena_3d \u001b[38;5;241m=\u001b[39m get_3d_arena(arena_path, extrinsics, intrinsics)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# get the backprojections and the frame points:\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m backprojections, frame_points3d \u001b[38;5;241m=\u001b[39m \u001b[43mbackproject_triangulated_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextrinsics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintrinsics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcam_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marena_3d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m#plot the frame in 3d\u001b[39;00m\n\u001b[0;32m     35\u001b[0m plot3d_frame(frame_points3d, arena_3d)\n",
      "Cell \u001b[1;32mIn[28], line 30\u001b[0m, in \u001b[0;36mbackproject_triangulated_points\u001b[1;34m(xarray_ds, extrinsics, intrinsics, frame_n, cam_names, arena_3d)\u001b[0m\n\u001b[0;32m     24\u001b[0m  \u001b[38;5;66;03m# Now shape is (keypoints, space, individuals)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Initialize dictionary to store back-projected points for each camera\u001b[39;00m\n\u001b[0;32m     28\u001b[0m arena2d \u001b[38;5;241m=\u001b[39m mcc\u001b[38;5;241m.\u001b[39mproject_points(arena_3d, extrinsics, camera_matrices)\n\u001b[1;32m---> 30\u001b[0m back_projected \u001b[38;5;241m=\u001b[39m \u001b[43mmcc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproject_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextrinsics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcamera_matrices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m back_projected_points \u001b[38;5;241m=\u001b[39m {camera: [points, arena] \u001b[38;5;28;01mfor\u001b[39;00m camera, points, arena \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(cam_names, back_projected, arena2d)}\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m back_projected_points, frame_points\n",
      "File \u001b[1;32mc:\\users\\sneurobiology\\code\\multicam-calibration\\multicam_calibration\\geometry.py:305\u001b[0m, in \u001b[0;36mproject_points\u001b[1;34m(points, extrinsics, camera_matrix, dist_coefs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;66;03m# Rotate and translate points\u001b[39;00m\n\u001b[0;32m    304\u001b[0m T \u001b[38;5;241m=\u001b[39m get_transformation_matrix(extrinsics)\n\u001b[1;32m--> 305\u001b[0m points_cam \u001b[38;5;241m=\u001b[39m \u001b[43mapply_rigid_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# Apply radial distortion\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dist_coefs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\users\\sneurobiology\\code\\multicam-calibration\\multicam_calibration\\geometry.py:151\u001b[0m, in \u001b[0;36mapply_rigid_transform\u001b[1;34m(transform, points)\u001b[0m\n\u001b[0;32m    148\u001b[0m     transform \u001b[38;5;241m=\u001b[39m get_transformation_matrix(transform)\n\u001b[0;32m    150\u001b[0m pts \u001b[38;5;241m=\u001b[39m euclidean_to_homogenous(points)\n\u001b[1;32m--> 151\u001b[0m points_transformed \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m points_transformed\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with remapped shapes [original->remapped]: (5,4,4)->(5,newaxis,newaxis) (13,4,1)->(13,newaxis,newaxis)  and requested shape (4,1)"
     ]
    }
   ],
   "source": [
    "backprojections_plots(mcc_ds, 0, slp_dir, calibration_path, arena_path) # !  the issue could be with the previous triangulation? or that here movement is not updated so we have to re run the triangulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
